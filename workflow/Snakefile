#Get input files
pacbio = config["pacbio"]
hicF = config["hicF"]
hicR = config["hicR"]
HAPS = ["hap1", "hap2"]
#Check if ONT reads are defined
ont = config["ont"]
#are the ONT reads R10, then maybe do assembly based on those instead of HiFi
r10 = config["r10"]

print()
shell(f"mkdir -p input")
if pacbio:
    shell(f"echo \"Input PacBio reads: {pacbio}\"")
    shell(f"ln -sf {pacbio} input/pacbio.fastq.gz")
if ont:
    shell(f"echo \"Input ONT reads: {ont}\"")
    shell(f"ln -sf {ont} input/ont.fastq.gz")
if hicF and hicR:
    shell(f"echo \"Input HiC reads: {hicF}, {hicR}\"")
    shell(f"ln -sf {hicF} input/hicF.fastq.gz")
    shell(f"ln -sf {hicR} input/hicR.fastq.gz")

#Decide which oatk analysis to run
def oatk_isPlant():
    output = []
    if config["oatk_isPlant"] == True:
        if config["pacbio"]:
            output.append("results/organelles/pacbio/oatk.pltd.ctg.fasta")
        if config["ont"]:
            output.append("results/organelles/ont/oatk.pltd.ctg.fasta")
    else:
        if config["pacbio"]:
            output.append("results/organelles/pacbio/oatk.mito.ctg.fasta")
        if config["ont"]:
            output.append("results/organelles/ont/oatk.mito.ctg.fasta")
    return(output)

def genomescope_out(wildcards):
    files = []
    if config["pacbio"]:
        files.extend(expand("results/pre_assembly/genomescope/pacbio_genomescope_ploidy{ploidy}.out", ploidy=config["GS_ploidy_range"]))
    if config["ont"]:
        files.extend(expand("results/pre_assembly/genomescope/ont_genomescope_ploidy{ploidy}.out", ploidy=config["GS_ploidy_range"]))
    return(files)

def smudgeplot_out(wildcards):
    files = []
    if config["pacbio"]:
        files.append("results/pre_assembly/smudgeplot/pacbio_smudgeplot.pdf")
    if config["ont"]:
        files.append("results/pre_assembly/smudgeplot/ont_smudgeplot.pdf")
    return(files)

def read_stats(wildcards):
    files = []
    if hicF and hicR:
        files.extend(["results/stats/hicF.stats", "results/stats/hicR.stats"])
    if config["pacbio"]:
        files.append("results/stats/pacbio.stats")
    if config["ont"]:
        files.append("results/stats/ont.stats")
    return(files)

def get_reads(wildcards):
    output = {}
    if config["pacbio"]:
        output["hifi"] = rules.hifiadapterfilt.output.pacbioFilt
    if config["ont"]:
        output["ont"] = config["ont"]
    return(output)

def asm_reads(wildcards):
    if config["pacbio"] and not config["ont"]:
        return(rules.hifiadapterfilt.output.pacbioFilt)
    elif config["pacbio"] and config["r10"]:
        return(ont)
    else:
        return([rules.hifiadapterfilt.output.pacbioFilt, config["ont"]])

def gen_linkread_cmd(wildcards):
    cmd = ""
    if config["ont"]:
        cmd += f'ln -sf ../input/ont.fastq.gz ./ont.fastq.gz\n'
    if config["pacbio"] and not config["ont"]:
        cmd += f'ln -sf ../{rules.hifiadapterfilt.output.pacbioFilt} ./pacbio.filt.fastq.gz\n'
        return(cmd)
    if config["pacbio"] and not config["r10"]:
        cmd += f'ln -sf ../{rules.hifiadapterfilt.output.pacbioFilt} ./pacbio.filt.fastq.gz\n'
        return(cmd)
    return(cmd)

def hifiasm_mode(wildcards):
    if config["ont"] and config["r10"]:
        ont = config["ont"].split("/")[-1]
        return("--ont ont.fastq.gz")
    elif config["ont"] and config["pacbio"]:
        ont = config["ont"].split("/")[-1]
        return("--ul ont.fastq.gz pacbio.filt.fastq.gz")
    elif config["pacbio"]:
        return("pacbio.filt.fastq.gz")

def minimap_mode(wildcards):
    if pacbio:
        return("map-hifi")
    else:
        return("map-ont")

def prio_reads(wildcards):
    if config["pacbio"] and not config["r10"]:
        return("input/pacbio.fastq.gz")
    else:
        return("input/ont.fastq.gz")

def assembly_out(wildcards):
    output = []
    if config["haploid"]:
        output.append("results/assembly/busco_assembly.bp.p_ctg_"+config["busco_lineage"])
        if hicF and hicR:
            output.append("results/scaffolding/busco_haploid_scaffolds_final_"+config["busco_lineage"])
    elif hicF and hicR:
        output.extend(expand("results/assembly/busco_assembly.hic.{hap}.p_ctg_{lineage}", lineage=config["busco_lineage"], hap=HAPS))
        output.extend(expand("results/scaffolding/busco_{hap}_scaffolds_final_{lineage}", lineage=config["busco_lineage"], hap=HAPS))
    else:
        output.extend(expand("results/assembly/busco_assembly.bp.{hap}.p_ctg_{lineage}", lineage=config["busco_lineage"], hap=HAPS))
    return(output)

def decontam_out(wildcards):
    output = []
    if config["haploid"]:
        output.append("results/decontamination/haploid/busco_haploid_final.decon_"+config["busco_lineage"])
    else:
        output.extend(expand("results/decontamination/{hap}/busco_{hap}_final.decon_{lineage}", lineage=config["busco_lineage"], hap=HAPS))
    return(output)

def fcs_input(wildcards):
    if config["haploid"]:
        if hicF and hicR:
            return("results/scaffolding/haploid_scaffolds_final.fa")
        else:
            return("results/assembly/assembly.bp.p_ctg.fa")
    elif hicF and hicR:
        return("results/scaffolding/{hap}_scaffolds_final.fa")
    else:
        return("results/assembly/assembly.bp.{hap}.p_ctg.fa")

def concat_in(wildcards):
    output = {}
    if config["haploid"]:
        output["haploid"] = "results/decontamination/haploid/haploid_final.decon.fa"
    else:
        output["hap1"] = "results/decontamination/hap1/hap1_final.decon.fa"
        output["hap2"] = "results/decontamination/hap2/hap2_final.decon.fa"
    return(output)

def curation_out(wildcards):
    if hicF and hicR:
        output = []
        for q in ["", "q5.", "q10."]:
            for hr in ["", "hr."]:
                output.append(f"results/curation/Scaff_HiC.mapping.{q}{hr}final.pretext")
        return(output)
    else:
        return("software_versions.txt")
   
#Define rules that do not need to be submitted to the cluster
localrules: read_statistics, concat_scaff, update_pretext, print_versions

#Summary rule to run full pipeline (pre-assembly, assembly, scaffolding)
rule all:
    input:
        genomescope_out,
        smudgeplot_out,
        assembly_out,
        decontam_out,
        oatk_isPlant(),
        read_stats,
        curation_out,
        "software_versions.txt"

#Summary rule to run the full pipeline, but without curation
rule all_nocuration:
    input:
        genomescope_out,
        smudgeplot_out,
        assembly_out,
        expand("results/decontamination/{hap}/busco_{hap}_final.decon_{lineage}", lineage=config["busco_lineage"], hap=HAPS),
        oatk_isPlant(),
        read_stats,
        "software_versions.txt"
        
#Summary rule to run all pre-assembly steps
rule pre_assembly:
    input:
        genomescope_out,
        smudgeplot_out,
        "software_versions.txt"

#General rule for running only primary assembly and busco
rule assembly:
    input:
        assembly_out,
        "software_versions.txt"
     
#General rule for generationg a decontaminated assembly, but without running busco
rule decontamination:
    input:
        assembly_out,
        expand("results/decontamination/{hap}/busco_{hap}_final.decon_{lineage}", lineage=config["busco_lineage"], hap=HAPS),
        "software_versions.txt"
        
#Rule for creating organelle assembly only        
rule organelles:
    input:
        oatk_isPlant()

rule read_statistics:
    output:
        stats = "results/stats/{tech}.stats"
    input:
        reads = "input/{tech}.fastq.gz"
    shell:
        r"""
        seqkit stats -a {input.reads} > {output.stats}
        """

#Filter PacBio HiFi reads
rule hifiadapterfilt:
    output:
        pacbioFilt = "results/pacbio/pacbio.filt.fastq.gz"
    input:
        config["pacbio"]
    resources:
        ntasks = config["adapterfilt_threads"]
    params:
        threads = config["adapterfilt_threads"],
        installdir = config["adapterfilt_install_dir"]
    shell:
        r"""
        export PATH={params.installdir}/DB:{params.installdir}:$PATH
        mkdir -p pbfilt_temp
        cd pbfilt_temp
        ln -sf {input} ./
        mkdir -p tmp
        export TMPDIR=./tmp
        pbadapterfilt.sh \
            -t {params.threads} \
            -o filtered
        mv filtered/*filt.fastq.gz ../{output.pacbioFilt}
        rm -r -f ./tmp
        cd ..
        rm -r -f pbfilt_temp
        """

#Count k-mers for genomescope and smudgeplot
rule count_kmers:
    output:
        db_ktab = temp("results/pre_assembly/{tech}_reads.kmer.db.ktab"),
        db_hist = temp("results/pre_assembly/{tech}_reads.kmer.db.hist"),
        hist = temp("results/pre_assembly/{tech}_reads.histo")
    input:
        "input/{tech}.fastq.gz"
    resources:
        ntasks = config["FastK_t"],
        time = config["FastK_time"] 
    params:
        k = config["FastK_k"],
        t = config["FastK_t"],
        m = config["FastK_m"]
    shell:
        r"""
        mkdir -p {wildcards.tech}_fastk_temp
        FastK -v -t1 \
         -T{params.t} \
         -k{params.k} \
         -M{params.m} \
         -P{wildcards.tech}_fastk_temp \
         {input} \
         -N{wildcards.tech}_reads.kmer.db
        Histex -G {wildcards.tech}_reads.kmer.db \
         > {output.hist}
        mv {wildcards.tech}_reads.kmer.db* .{wildcards.tech}_reads.kmer.db* results/pre_assembly/
        rm -r {wildcards.tech}_fastk_temp
        """

#Run Genomescope
rule genomescope:
    output:
        "results/pre_assembly/genomescope/{tech}_genomescope_ploidy{ploidy}.out"
    input:
        rules.count_kmers.output.hist
    resources:
        time = config["GS_time"]
    params:
        ploidy_range = config["GS_ploidy_range"],
        k = config["FastK_k"]
    shell:
        r"""
        genomescope2 \
         -i {input} \
         -o results/pre_assembly/genomescope/{wildcards.tech}_ploidy{wildcards.ploidy} \
         -k {params.k} \
         -p {wildcards.ploidy} \
         1> results/pre_assembly/genomescope/{wildcards.tech}_genomescope_ploidy{wildcards.ploidy}.out \
         2> results/pre_assembly/genomescope/{wildcards.tech}_genomescope_ploidy{wildcards.ploidy}.err
        """

#Run Smudgeplot
rule smudgeplot:
    output:
        "results/pre_assembly/smudgeplot/{tech}_smudgeplot.pdf"
    input:
        db_ktab = rules.count_kmers.output.db_ktab,
        db_hist = rules.count_kmers.output.db_hist
    params:
        t = config["FastK_t"]
    resources:
        time = config["smudge_time"]
    conda:
        config["smudgeplot_conda_env"]
    shell:
        r"""
        smudgeplot.py hetmers results/pre_assembly/{wildcards.tech}_reads.kmer.db -L 10 -t {params.t} -o results/pre_assembly/smudgeplot/{wildcards.tech}_smudgeplot_pairs
        smudgeplot.py all results/pre_assembly/smudgeplot/{wildcards.tech}_smudgeplot_pairs_text.smu -o results/pre_assembly/smudgeplot/{wildcards.tech}
        """

#Perform genome assembly with hifiasm using pacbio reads and hic reads
rule assembly_hifiasm:
    output:
        hap1 = "results/assembly/assembly.hic.hap1.p_ctg.fa",
        hap2 = "results/assembly/assembly.hic.hap2.p_ctg.fa"
    input:
        unpack(get_reads),
        hicF = hicF,
        hicR = hicR
    resources:
        time = config["hifiasm_cluster_time"],
        mem_per_cpu = config["hifiasm_mem_per_cpu"],
        ntasks = config["hifiasm_threads"],
        partition = config["hifiasm_partition"]
    params:
        threads = config["hifiasm_threads"],
        mode = hifiasm_mode,
        linkreads = gen_linkread_cmd
    shell:
        r"""
        export CWD=$PWD
        mkdir -p assembly_tmp 
        cd assembly_tmp
        ln -sf {input.hicF} ./hicF.fastq.gz
        ln -sf {input.hicR} ./hicR.fastq.gz
        {params.linkreads}
        hifiasm \
            -o assembly \
            --dual-scaf \
            -t{params.threads} \
            --h1 hicF.fastq.gz \
            --h2 hicR.fastq.gz \
            {params.mode} 
        mv assembly.* $CWD/results/assembly
        awk '/^S/{{print ">"$2"\n"$3}}' $CWD/results/assembly/assembly.hic.hap1.p_ctg.gfa \
            | fold > $CWD/{output.hap1}
        awk '/^S/{{print ">"$2"\n"$3}}' $CWD/results/assembly/assembly.hic.hap2.p_ctg.gfa \
            | fold > $CWD/{output.hap2}
        cd $CWD && rm -r assembly_tmp
        if [ -f {output.hap1} ]; then
            rm results/assembly/*bin
        fi
        """

rule assembly_hifiasm_nohic:
    output:
        hap1 = "results/assembly/assembly.bp.hap1.p_ctg.fa",
        hap2 = "results/assembly/assembly.bp.hap2.p_ctg.fa"
    input:
        unpack(get_reads)
    resources:
        time = config["hifiasm_cluster_time"],
        mem_per_cpu = config["hifiasm_mem_per_cpu"],
        ntasks = config["hifiasm_threads"],
        partition = config["hifiasm_partition"]
    params:
        threads = config["hifiasm_threads"],
        mode = hifiasm_mode,
        linkreads = gen_linkread_cmd
    shell:
        r"""
        mkdir -p assembly_tmp 
        cd assembly_tmp
        {params.linkreads}
        hifiasm \
            -o assembly \
            --dual-scaf \
            -t{params.threads} \
            {params.mode} 
        mv assembly.* ../results/assembly
        awk '/^S/{{print ">"$2"\n"$3}}' ../results/assembly/assembly.bp.hap1.p_ctg.gfa \
            | fold > ../{output.hap1}
        awk '/^S/{{print ">"$2"\n"$3}}' ../results/assembly/assembly.bp.hap2.p_ctg.gfa \
            | fold > ../{output.hap2}
        cd .. && rm -r assembly_tmp
        if [ -f {output.hap1} ]; then
            rm results/assembly/*bin
        fi
        """

rule assembly_hifiasm_haploid:
    output:
        assembly = "results/assembly/assembly.bp.p_ctg.fa"
    input:
        unpack(get_reads)
    resources:
        time = config["hifiasm_cluster_time"],
        mem_per_cpu = config["hifiasm_mem_per_cpu"],
        ntasks = config["hifiasm_threads"],
        partition = config["hifiasm_partition"]
    params:
        threads = config["hifiasm_threads"],
        mode = hifiasm_mode,
        linkreads = gen_linkread_cmd
    shell:
        r"""
        mkdir -p assembly_tmp 
        cd assembly_tmp
        {params.linkreads}
        hifiasm \
            -l0 \
            -o assembly \
            -t{params.threads} \
            {params.mode} 
        mv assembly.* ../results/assembly
        awk '/^S/{{print ">"$2"\n"$3}}' ../results/assembly/assembly.bp.p_ctg.gfa \
            | fold > ../{output.assembly}
        cd .. && rm -r assembly_tmp
        if [ -f {output.assembly} ]; then
            rm results/assembly/*bin
        fi
        """

#Run busco on assembly
rule busco:
    output:
        directory(expand("results/{{dir}}/busco_{{assembly}}_{lineage}", lineage=config["busco_lineage"]))
    input:
        assembly = "results/{dir}/{assembly}.fa",
        busco = expand("{busco_db_dir}/{lineage}_odb10", busco_db_dir=config["busco_db_dir"], lineage=config["busco_lineage"])
    resources:
        mem_per_cpu = config["busco_mem"],
        ntasks = config["busco_threads"]
    params:
        lineage = config["busco_lineage"],
        threads = config["busco_threads"]
    shell:
        r"""
        busco \
            -i {input.assembly} \
            -l {input.busco} \
            -c {params.threads} \
            -m genome \
            --offline \
            --out_path results/{wildcards.dir} \
            -o busco_{wildcards.assembly}_{params.lineage} \
            --download_path /tmp
        """

#Create Meryl Database
rule create_meryl_db:
    output:
        temp(directory("results/scaffolding/meryl/assembly.hic.{hap}.p_ctg.meryl"))
    input:
        "results/assembly/assembly.hic.{hap}.p_ctg.fa"
    resources:
        ntasks = config["meryl_threads"]
    params:
        k = config["meryl_k"],
        t = config["meryl_threads"],
        m = config["meryl_memory"],
    shell:
        r"""
        meryl \
            k={params.k} \
            threads={params.t} \
            memory={params.m} \
            count \
            output {output} \
            {input}
        """
        
#Run meryl for filtering Hi-C reads before scaffolding
rule meryl_filter:
    output:
        hicFwoH1 = "results/scaffolding/meryl/hicF_hap2.fastq.gz",
        hicRwoH1 = "results/scaffolding/meryl/hicR_hap2.fastq.gz",
        hicFwoH2 = "results/scaffolding/meryl/hicF_hap1.fastq.gz",
        hicRwoH2 = "results/scaffolding/meryl/hicR_hap1.fastq.gz"
    input:
        hicF = hicF,
        hicR = hicR,
        meryl_hap1 = "results/scaffolding/meryl/assembly.hic.hap1.p_ctg.meryl",
        meryl_hap2 = "results/scaffolding/meryl/assembly.hic.hap2.p_ctg.meryl"
    resources:
        ntasks = config["meryl_threads"]
    shell:
        r"""
        meryl difference \
            {input.meryl_hap1} \
            {input.meryl_hap2} \
            output results/scaffolding/meryl/only_hap1.meryl
        meryl difference \
            {input.meryl_hap2} \
            {input.meryl_hap1} \
            output results/scaffolding/meryl/only_hap2.meryl
        meryl-lookup \
            -exclude \
            -sequence {input.hicF} {input.hicR} \
            -mers results/scaffolding/meryl/only_hap1.meryl \
            -output {output.hicFwoH1} {output.hicRwoH1}
        meryl-lookup \
            -exclude \
            -sequence {input.hicF} {input.hicR} \
            -mers results/scaffolding/meryl/only_hap2.meryl \
            -output {output.hicFwoH2} {output.hicRwoH2}
        if [ -f {output.hicFwoH1} ]; then
            rm -r results/scaffolding/meryl/only*
        fi
        """

#Prepare filtered Hi-C reads for scaffolding
rule map_hic:
    output:
        mapping = temp("results/scaffolding/{hap}_mapping.bam")
    input: 
        assembly = "results/assembly/assembly.hic.{hap}.p_ctg.fa",
        hicF = "results/scaffolding/meryl/hicF_{hap}.fastq.gz",
        hicR = "results/scaffolding/meryl/hicR_{hap}.fastq.gz"
    resources:
        ntasks = config["yahs_threads"]
    params:
        t = config["yahs_threads"]
    shell:
        r"""
        bwa index {input.assembly}
        samtools faidx {input.assembly}
        bwa mem \
            -t {params.t} \
            -R '@RG\tSM:{wildcards.hap}\tID:{wildcards.hap}' \
            -5SPM \
            {input.assembly} {input.hicF} {input.hicR} \
        | samtools view -bu - > {output.mapping}
        """

rule map_hic_haploid:
    output:
        mapping = temp("results/scaffolding/haploid_mapping.bam")
    input:
        assembly = "results/assembly/assembly.bp.p_ctg.fa",
        hicF = hicF,
        hicR = hicR
    resources:
        ntasks = config["yahs_threads"]
    params:
        t = config["yahs_threads"]
    shell:
        r"""
        bwa index {input.assembly}
        samtools faidx {input.assembly}
        bwa mem \
         -t {params.t} \
         -R '@RG\tSM:haploid\tID:haploid' \
         -5SPM \
         {input.assembly} {input.hicF} {input.hicR} \
        | samtools view -bu - > {output.mapping}
        """

rule prepare_hic:
    output:
        markdup = temp("results/scaffolding/{hap}_hic_markdup.sort_n.bam")
    input:
        mapping = "results/scaffolding/{hap}_mapping.bam"
    resources:
        ntasks = config["yahs_threads"]
    params:
        t = config["yahs_threads"]
    shell:
        r"""
        samtools sort \
            -@{params.t} \
            -n \
            -T results/scaffolding/{wildcards.hap}_tmp_n \
            -O bam \
            -o results/scaffolding/{wildcards.hap}_mapping.sorted.bam \
            {input.mapping}
        samtools fixmate -mr \
            results/scaffolding/{wildcards.hap}_mapping.sorted.bam \
            results/scaffolding/{wildcards.hap}_mapping.fixmate.bam
        samtools sort \
            -@{params.t} \
            -T results/scaffolding/{wildcards.hap}_hic_tmp \
            -O bam \
            -o results/scaffolding/{wildcards.hap}_mapping.fixmate.sorted.bam \
            results/scaffolding/{wildcards.hap}_mapping.fixmate.bam
        samtools markdup -rs \
            -@{params.t}\
            results/scaffolding/{wildcards.hap}_mapping.fixmate.sorted.bam \
            results/scaffolding/{wildcards.hap}_mapping.markdup.bam \
            2> results/scaffolding/{wildcards.hap}_hic_markdup.stats
        samtools sort \
            -@{params.t} \
            -n \
            -T results/scaffolding/{wildcards.hap}_temp_n \
            -O bam \
            -o {output.markdup} \
            results/scaffolding/{wildcards.hap}_mapping.markdup.bam
        if [ -f {output.markdup} ]; then
                rm results/scaffolding/{wildcards.hap}_mapping.sorted.bam \
                results/scaffolding/{wildcards.hap}_mapping.fixmate.bam \
                results/scaffolding/{wildcards.hap}_mapping.fixmate.sorted.bam \
                results/scaffolding/{wildcards.hap}_mapping.markdup.bam
        fi
        """

#Run scaffolding with yahs
rule scaffold_hap:
    output:
        "results/scaffolding/{hap}_scaffolds_final.fa"
    input:
        assembly = "results/assembly/assembly.hic.{hap}.p_ctg.fa",
        bamfile = "results/scaffolding/{hap}_hic_markdup.sort_n.bam"
    resources:
        ntasks = config["yahs_threads"],
        time = config["yahs_cluster_time"],
    shell:
        r"""
        yahs {input.assembly} {input.bamfile} \
            -o results/scaffolding/{wildcards.hap} \
            1> results/scaffolding/yahs_{wildcards.hap}.out \
            2> results/scaffolding/yahs_{wildcards.hap}.err
        gfastats {output} \
            > results/scaffolding/{wildcards.hap}_scaffolds_final.stats
        if [ -f {output} ]; then
            rm results/scaffolding/{wildcards.hap}.bin
        fi
        """

rule scaffold_haploid:
    output:
        "results/scaffolding/haploid_scaffolds_final.fa"
    input:
        assembly = "results/assembly/assembly.bp.p_ctg.fa",
        bamfile = "results/scaffolding/haploid_hic_markdup.sort_n.bam"
    resources:
        ntasks = config["yahs_threads"],
        time = config["yahs_cluster_time"],
    shell:
        r"""
        yahs {input.assembly} {input.bamfile} \
            -o results/scaffolding/haploid \
            1> results/scaffolding/yahs_haploid.out \
            2> results/scaffolding/yahs_haploid.err
        gfastats {output} \
            > results/scaffolding/haploid_scaffolds_final.stats
        if [ -f {output} ]; then
            rm results/scaffolding/haploid.bin
        fi
        """
 
#Remove adaptors and vector contamination
rule fcs_adaptor:
    output:
        "results/decontamination/{hap}/{hap}_final.clean.fa"
    input:
        fcs_input
    resources:
        time = config["fcs_adaptor_time"],
        mem_per_cpu = config["fcs_adaptor_mem"],
    params:
        fcs_path = config["fcs_path"],
        fcs_image = config["fcs_adaptor_image"]
    shell:
        r"""
        mkdir -p results/decontamination/{wildcards.hap}/adaptor_output
        bash {params.fcs_path}/run_fcsadaptor.sh \
            --fasta-input {input} \
            --output-dir results/decontamination/{wildcards.hap}/adaptor_output \
            --euk \
            --container-engine singularity \
            --image {params.fcs_path}/fcs-adaptor.sif
        sed 's/lcl|/clean/g' \
            results/decontamination/{wildcards.hap}/adaptor_output/cleaned_sequences/*.fa > {output}
        """
 
 #Run decontamination pipeline
rule fcs_gx:
    output:
        "results/decontamination/{hap}/{hap}_final.decon.fa"
    input:
        "results/decontamination/{hap}/{hap}_final.clean.fa"
    resources:
        time = config["fcs_gx_time"],
        mem_per_cpu = config["fcs_gx_mem"],
        partition = config["fcs_gx_partition"],
        ntasks = config["fcs_threads"]
    params:
        fcs_path = config["fcs_path"],
        fcs_threads = config["fcs_threads"],
        fcs_image = config["fcs_gx_image"],
        fcs_db = config["fcs_gx_db"],
        taxid = config["taxid"]
    shell:
        r"""
        mkdir -p results/decontamination/{wildcards.hap}/gx_output
        echo "GX_NUM_CORES={params.fcs_threads}" > results/decontamination/{wildcards.hap}/env.txt
        python3 {params.fcs_path}/fcs.py \
            --image {params.fcs_image} \
            screen genome \
            --fasta {input} \
            --out-dir results/decontamination/{wildcards.hap}/gx_output \
            --gx-db {params.fcs_db} \
            --tax-id {params.taxid}
        cat {input} \
        | python3 {params.fcs_path}/fcs.py \
            --image={params.fcs_image} \
            clean genome \
            --action-report results/decontamination/{wildcards.hap}/gx_output/*.fcs_gx_report.txt \
            --output {output} \
            --contam-fasta-out results/decontamination/{wildcards.hap}/contam.fasta
        """
        
rule run_oatk_plant:
    output:
        "results/organelles/{tech}/oatk.pltd.ctg.fasta"
    input:
        "input/{tech}.fastq.gz"
    resources:
        tasks = config["oatk_threads"],
        mem_per_cpu = config["oatk_mem"]
    params:
        oatk_install = config["oatk_dir"],
        oatk_db = config["oatk_db"],
        lineage = config["oatk_lineage"],
        k = config["oatk_k"],
        c = config["oatk_c"],
        threads = config["oatk_threads"]
    shell:
        """
        {params.oatk_install}/oatk \
            -k {params.k} \
            -c {params.c} \
            -t {params.threads} \
            --nhmmscan nhmmscan \
            -m {params.oatk_db}/{params.lineage}_mito.fam \
            -p {params.oatk_db}/{params.lineage}_pltd.fam \
            -o results/organelles/{wildcards.tech}/oatk \
            {input} \
        || touch {output}
        """

rule run_oatk_nonplant:
    output:
        "results/organelles/{tech}/oatk.mito.ctg.fasta"
    input:
        "input/{tech}.fastq.gz"
    resources:
        ntasks = config["oatk_threads"],
        mem_per_cpu = config["oatk_mem"]
    params:
        oatk_install = config["oatk_dir"],
        oatk_db = config["oatk_db"],
        lineage = config["oatk_lineage"],
        k = config["oatk_k"],
        c = config["oatk_c"],
        threads = config["oatk_threads"],
    shell:
        """
        {params.oatk_install}/oatk \
            -k {params.k} \
            -c {params.c} \
            -t {params.threads} \
            --nhmmscan nhmmscan \
            -m {params.oatk_db}/{params.lineage}_mito.fam \
            -o results/organelles/{wildcards.tech}/oatk \
            {input} \
        || touch {output}
        """     

rule concat_scaff:
    output:
        "results/curation/data/ref.fa"
    input:
        unpack(concat_in)
    run:
        if "haploid" in input.keys():
            shell("ln -sf ${{PWD}}/{input.haploid} ${{PWD}}/{output}")
        else:
            shell('cat {input.hap1} | sed "s/>/>H1_/g" > {output}')
            shell('cat {input.hap2} | sed "s/>/>H2_/g" >> {output}')

rule create_pretext:
    output:
        q0 = "results/curation/Scaff_HiC.mapping.pretext",
        q5 = "results/curation/Scaff_HiC.mapping.q5.pretext",
        q10 = "results/curation/Scaff_HiC.mapping.q10.pretext",
        q0hr = "results/curation/Scaff_HiC.mapping.hr.pretext",
        q5hr = "results/curation/Scaff_HiC.mapping.q5.hr.pretext",
        q10hr = "results/curation/Scaff_HiC.mapping.q10.hr.pretext"
    input:
        hicF = hicF,
        hicR = hicR,
        scaff = rules.concat_scaff.output
    resources:
        mem_per_cpu = config["curation_mapping_mem"],
        ntasks = config["curation_mapping_threads"],
        time = config["curation_time"]
    shell:
        r"""
        [ -f {input.scaff}.bwt ] || bwa index {input.scaff}
        bwa mem -t {resources.ntasks} -5SPM \
            {input.scaff} {input.hicF} {input.hicR} \
        | samtools view -buS - \
        | samtools sort -@3 -n -T tmp1 -O bam - \
        | samtools fixmate -mr - - \
        | samtools sort -@3 -T tmp2 -O bam - \
        | samtools markdup -rsS - - \
            2> results/curation/hic_markdup.stats \
        | samtools sort -@3 -T tmp3 -O bam \
        > results/curation/HiC_BotHapScaff.markdup.sort.bam
        samtools view -h results/curation/HiC_BotHapScaff.markdup.sort.bam \
        | PretextMap --highRes -o {output.q0hr} --sortby length --sortoder descend --mapq 0
        samtools view -h results/curation/HiC_BotHapScaff.markdup.sort.bam \
        | PretextMap --highRes -o {output.q5hr} --sortby length --sortoder descend --mapq 5
        samtools view -h results/curation/HiC_BotHapScaff.markdup.sort.bam \
        | PretextMap --highRes -o {output.q10hr} --sortby length --sortoder descend --mapq 10
        samtools view -h results/curation/HiC_BotHapScaff.markdup.sort.bam \
        | PretextMap -o {output.q0} --sortby length --sortoder descend --mapq 0
        samtools view -h results/curation/HiC_BotHapScaff.markdup.sort.bam \
        | PretextMap -o {output.q5} --sortby length --sortoder descend --mapq 5
        samtools view -h results/curation/HiC_BotHapScaff.markdup.sort.bam \
        | PretextMap -o {output.q10} --sortby length --sortoder descend --mapq 10

        """

rule curation_coverage:
    output:
        "results/curation/Scaff_coverage.bw"
    input:
        reads = prio_reads,
        scaff = rules.concat_scaff.output
    resources:
        mem_per_cpu = config["curation_mapping_mem"],
        ntasks = config["curation_mapping_threads"]
    params:
        mode = minimap_mode
    shell:
        r"""
        minimap2 \
            -ax {params.mode} \
            -t {resources.ntasks} \
            {input.scaff} {input.reads} \
        | samtools sort -@{resources.ntasks} -O BAM -o results/curation/Scaff_coverage.bam
        samtools view -b -F 256 results/curation/Scaff_coverage.bam > results/curation/Scaff_coverage.prim.bam
        samtools index results/curation/Scaff_coverage.prim.bam
        bamCoverage -b results/curation/Scaff_coverage.prim.bam -o {output}
        """

rule curation_repeats:
    output:
        "results/curation/out/Scaff_repeat_density.bw"
    input:
        scaff = rules.concat_scaff.output
    params:
        installdir = config["curation_install_dir"]
    resources:
        mem_per_cpu = config["curation_mapping_mem"],
        ntasks = config["curation_mapping_threads"]
    shell:
        r"""
        mkdir -p results/curation/tmp_repeat results/curation/out
        export SINGULARITY_BIND="\
            $PWD/results/curation/data:/data,\
            $PWD/results/curation/out:/output,\
            $PWD/results/curation/tmp_repeat:/tmp,\
            "
        singularity run {params.installdir}/runRepeat.sif -t Scaff || touch {output}
        rm -rf results/curation/tmp_repeat
        """

rule curation_gaps:
    output:
        "results/curation/out/Scaff_gap.bedgraph"
    input:
        scaff = rules.concat_scaff.output
    params:
        installdir = config["curation_install_dir"]
    resources:
        mem_per_cpu = config["curation_mapping_mem"],
        ntasks = config["curation_mapping_threads"]
    shell:
        r"""
        mkdir -p results/curation/tmp_gaps results/curation/out
        export SINGULARITY_BIND="\
            $PWD/results/curation/data:/data,\
            $PWD/results/curation/out:/output,\
            $PWD/results/curation/tmp_gaps:/tmp,\
            "
        singularity run {params.installdir}/runGap.sif -t Scaff || touch {output}
        rm -rf results/curation/tmp_gaps
        """

rule curation_telomeres:
    output:
        "results/curation/out/Scaff_telomere.bedgraph"
    input:
        scaff = rules.concat_scaff.output
    params:
        installdir = config["curation_install_dir"],
        telo = config["curation_telomere_rep"]
    resources:
        mem_per_cpu = config["curation_mapping_mem"],
        ntasks = config["curation_mapping_threads"]
    shell:
        r"""
        mkdir -p results/curation/tmp_telo results/curation/out
        export SINGULARITY_BIND=" \
            $PWD/results/curation/data:/data,\
            $PWD/results/curation/out:/output,\
            $PWD/results/curation/tmp_telo:/tmp,\
            "
        singularity run {params.installdir}/runTelo.sif -t Scaff -s {params.telo} || touch {output}
        rm -rf results/curation/tmp_telo
        """

rule update_pretext:
    output:
        pretext = "results/curation/{filename}.final.pretext"
    input:
        pretext = "results/curation/{filename}.pretext",
        cov = rules.curation_coverage.output,
        gaps = rules.curation_gaps.output,
        reps = rules.curation_repeats.output,
        telo = rules.curation_telomeres.output
    shell:
        r"""
        set +e
        cp {input.pretext} {output.pretext}
        bigWigToBedGraph {input.cov} /dev/stdout \
        | PretextGraph -i {output.pretext} -n "Coverage" \
        || touch {output.pretext}
        bigWigToBedGraph {input.reps} /dev/stdout \
        | PretextGraph -i {output.pretext} -n "Repeat density" \
        || touch {output.pretext}
        cat {input.gaps} \
        | PretextGraph -i {output.pretext} -n "Gaps" \
        || touch {output.pretext}
        cat {input.telo} \
        | awk -v OFS="\t" '{{$4 *= 1000; print}}' \
        | PretextGraph -i {output.pretext} -n "Telomers" \
        || touch {output.pretext}
        """
        
#Print software versions to file
rule print_versions:
    output:
        "software_versions.txt"
    params:
        hifiadapterfilt = config["adapterfilt_install_dir"],
        fcs_path = config["fcs_path"],
        oatk_install = config["oatk_dir"]
    shell:
        r"""
        printf "Conda software versions:\n" > {output}
        conda list -e | grep -v "^#" >> {output}
        printf "\nOther software versions:\n" >> {output}
        printf "\nHiFi Adapterfilt version:\t" >> {output}
        bash {params.hifiadapterfilt}/hifiadapterfilt.sh --version >> {output}
        printf "\nNCBI FCS versions:\n" >> {output}
        printf "fcsadaptor:\t" >> {output}
        cat {params.fcs_path}/run_fcsadaptor.sh | grep "^DEFAULT_VERSION" >> {output}
        printf "fcs.py:\t" >> {output}
        cat {params.fcs_path}/fcs.py | grep "^DEFAULT_VERSION" >> {output}
        printf "oatk:\t" >> {output}
        {params.oatk_install}/oatk --version >> {output}
        """
